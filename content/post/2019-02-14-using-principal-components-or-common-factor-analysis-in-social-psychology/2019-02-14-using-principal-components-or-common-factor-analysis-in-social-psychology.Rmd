---
title: Using Principal Components or Common Factor Analysis in Social Psychology
author: Nick Michalak
date: '2019-02-14'
slug: using-principal-components-or-common-factor-analysis-in-social-psychology
categories:
  - common factor analysis
  - tutorial
  - principal components analysis
  - R
  - measurement
  - demonstration
  - reliability
tags:
  - common factor analysis
  - tutorial
  - principal component analysis
  - R
  - measurement
  - reliability
  - demonstration
image:
  caption: ''
  focal_point: ''
---

Note. I'm not done with this post but it's fun to build a new website and see your posts appear so pretty online ... so here it is!

# Multidimensional Scaling
> Multidimensional scaling is an exploratory technique that uses distances or disimilarities between objects to create a multidimensional representation of those objects in metric space. In other words, multidimensional scaling uses data about the distance (e.g., miles between cities) or disimilarity (e.g., how (dis)similar are apples and tomatoes?) among a set of objects to "search" for some metric space that represents those objects and their relations to each other. Metric space is a fancy term for a set of objects and some metric that satisfy a list of axioms.  

> Here is one way to represent the distance (d) axioms:

1. $$d_{ij} > d_{ii} = 0 \text{,  for } i \neq j.$$
2. $$d_{ij} = d_{ji}.$$
3. $$d_{ij} \leq d_{ik} + d_{kj}.$$  

> Here is one way to represent the similarity (s) axioms:  

1. $$s_{ii} > s_{ij}.$$
2. $$s_{ij} = s_ji.$$
3. $$\text{a large } s_{ij} \text{ implies } d_{ik} \approx d_{kj}.$$  

> The idea here is that the data and the axioms constrain the solution you get. For example, if you're making a map of U.S. cities—and you want a accurate map of the cities—then including 100,000 cities in your analysis will place more constraints on your solution than including 10 cities. More contraints in this case will give you a better picture of 10 cities and their relation to each other (e.g., New York is north of Miami) than fewer constrains.  
> This should be more clear in the example below.

## Install packages and/or load libraries
> I'll use these packages throughout this post.

```{r, warning = FALSE, message = FALSE}

# install.packages("tidyverse")
# install.packages("knitr")
# install.packages("haven")
# install.packages("maps")
# install.packages("psych")

library(tidyverse)
library(knitr)
library(haven)
library(maps)
library(psych)

```

## Data
> `help("UScitiesD")`  
> "UScitiesD gives “straight line” distances between 10 cities in the US."

```{r}

UScitiesD %>% 
  as.matrix() %>% 
  kable()

```

### Represent the distance matrix with colors
> 1. Convert the distance object into a `data.frame`  
> 2. Restructure the data.frame so each distance value gets its own row, and each distance value corresponds to two city names (even cities with themselves)  
> 3. Plot the distance values on tiles that are colored by the size of the distance

```{r, fig.width = 10.5, fig.height = 7.5}

UScitiesD %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  mutate(city1 = rownames(.)) %>% 
  gather(key = city2, value = distance, -city1) %>% 
  ggplot(mapping = aes(x = city1, y = city2, fill = distance, label = distance)) +
  geom_tile() +
  geom_text() +
  scale_fill_gradient2() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

### Metric Multidimensional Scaling (2-dimensions, like a map)
> `help("cmdscale")`  
> "Classical multidimensional scaling (MDS) of a data matrix. Also known as principal coordinates analysis (Gower, 1966)."

```{r}

# give it distance values and number of dimensions
# also ask for the function to output eigenvalues
cmdscale.fit1 <- cmdscale(UScitiesD, k = 2, eig = TRUE)

```

### Plot eigenvalues sorted by size (i.e., screeplot)
> You can use eigenvalues to give you a sense of how many dimensions can capture most of the information from original data. A "big" eigenvalue means a lot of information is contained in a given dimension. You can tell how big the eigenvalues are by looking a a plot of the digenvalues sorted by size. Analysts typically determine the number of dimensions to use by counting eigenvalues from left to right until the pattern of points flattens out (i.e., there is little leftover information contain in the remaining dimensions).

```{r}

tibble(index = 1:length(cmdscale.fit1$eig),
       eigenvalue = cmdscale.fit1$eig) %>% 
  ggplot(mapping = aes(x = index, y = eigenvalue)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = scales::comma)

```

### Store points from the fitted configuration/solution in a tibble `data.frame`

```{r}

cmdscale.data <- tibble(city = rownames(cmdscale.fit1$points),
                        dimension1 = cmdscale.fit1$points[, 1],
                        dimension2 = cmdscale.fit1$points[, 2])

```

#### Plot the solution

```{r}

cmdscale.data %>% 
  ggplot(mapping = aes(x = dimension2, y = dimension1, label = city)) +
  geom_point() +
  geom_label(nudge_y = 100)

```

#### Compare the solution above to a map of the U.S. below
> Because we only used pairwise distances among ten U.S. cities, the solution imperfectly represented real relations among these cities. For example, Miami seems to be in the right spot on the "Southeastern quadrant" of the plot, but New York and Washington D.C. are placed in the "Southwestern quadrant" of the plot.

```{r}

map_data("state") %>% 
  ggplot(mapping = aes(x = long, y = lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()

```

# Measuring variables we can't observe
> 

# Partitioning variance

## Common Variance

### Communality

## Unique Variance

### Specific Variance

### Error Variance

# SPSS Anxiety Questionnaire (SAQ)

## Description

### Read SPSS Anxiety Questionnaire data
> You can download these data [[**SAQ.sav**](https://github.com/nmmichalak/academic-kickstart/raw/master/static/post/2019-02-14-using-principal-components-or-common-factor-analysis-in-social-psychology/2019-02-14-using-principal-components-or-common-factor-analysis-in-social-psychology_files/data/SAQ.sav)]

```{r, warning = FALSE, message = FALSE}

saq <- read_spss(file = "data/SAQ.sav")

```

### Correlation matrix

```{r, fig.width = 15.75, fig.height = 11.25}

saq %>% 
  cor(use = "pairwise.complete.obs") %>% 
  round(2) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>%
  rename(item1 = rowname) %>% 
  gather(key = item2, value = r, -item1) %>% 
  ggplot(mapping = aes(x = item1, y = item2, fill = r, label = r)) +
  geom_tile() +
  geom_text() +
  scale_fill_gradient2() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```

### Histograms

```{r}

saq %>% 
  gather(key = variable, value = response) %>% 
  ggplot(mapping = aes(x = response)) +
  geom_histogram(binwidth = 1, color = "white") +
  facet_wrap(facets = ~ variable)

```

### Parallel Analysis

```{r}

fa.parallel(saq, fm = "minres", fa = "both")

```

# Principal Components Analysis

## all items

```{r}

principal(saq, rotate = "varimax") %>% 
  print(sort = TRUE)

# plot
principal(saq, rotate = "varimax") %>% 
  fa.diagram(sort = TRUE)

```

## 4 components

```{r}

principal(saq, nfactors = 4, rotate = "varimax") %>% 
  print(sort = TRUE)

# plot
principal(saq, nfactors = 4, rotate = "varimax") %>% 
  fa.diagram(sort = TRUE)

```

# Common Factor Analysis

## all items

```{r}

fa(saq, fm = "minres", rotate = "oblimin") %>% 
  print(sort = TRUE)

# plot
fa(saq, fm = "minres", rotate = "oblimin") %>% 
  fa.diagram(sort = TRUE)

```

## 6 factors

```{r}

fa(saq, nfactors = 6, fm = "minres", rotate = "oblimin") %>% 
  print(sort = TRUE)

# plot
fa(saq, nfactors = 6, fm = "minres", rotate = "oblimin") %>% 
  fa.diagram(sort = TRUE)

```

# General word of caution
> Above, I listed resources prepared by experts on these and related topics. Although I generally do my best to write accurate posts, don't assume my posts are 100% accurate or that they apply to your data or research questions. Trust statistics and methodology experts, not blog posts.
